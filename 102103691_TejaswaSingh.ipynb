{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opQHyHBJfkn9"
      },
      "source": [
        "# Name: Tejaswa Singh\n",
        "# Email: tsingh2_be21@thapar.edu\n",
        "# Roll No: 102103691\n",
        "# Group: 4CO24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS5Nbyk_fvbe"
      },
      "source": [
        "Question:\n",
        "\n",
        "Consider the paper: <https://arxiv.org/abs/1804.03209>\n",
        "\n",
        "  1. Read and summarise the paper in about 50 words.\n",
        "  2. Download the dataset in the paper, statistically analyse and\n",
        "     describe it, so that it may be useful for posterity. (Include code\n",
        "     snippets in your .ipynb file to evidence your analysis.)\n",
        "  3. Train a classifier so that you are able to distinguish the commands\n",
        "     in the dataset.\n",
        "  4. Report the performance results using standard benchmarks.\n",
        "  5. Record about 30 samples of each command in your voice and create a\n",
        "     new dataset (including a new user id for yourself).  You may use a\n",
        "     timer on your computer to synchronise.\n",
        "  6. Fine tune your classifier to perform on your voice.\n",
        "  7. Report the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5HF8ilJgGSQ"
      },
      "source": [
        "Solution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hykySLcfg63"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AVHSjypzQFv",
        "outputId": "514a2083-9779-4d7e-a43b-c08e5181e5e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('speech_commands_v0.02.tar.gz', <http.client.HTTPMessage at 0x7932e439c850>)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the dataset\n",
        "data_url = 'http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz'\n",
        "filename = 'speech_commands_v0.02.tar.gz'\n",
        "urllib.request.urlretrieve(data_url, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a5lOf-kzSYL"
      },
      "outputs": [],
      "source": [
        "# Extract the dataset\n",
        "if not os.path.exists('./speech_commands'):\n",
        "    tar = tarfile.open(filename, 'r:gz')\n",
        "    tar.extractall(path='./speech_commands')\n",
        "    tar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp2JoUDpzdmy",
        "outputId": "9afec449-94fa-4fa8-ccdc-fbef6d052a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['right', 'eight', 'two', 'on', 'dog', 'bed', 'no', 'nine', 'cat', 'one', 'up', 'five', 'backward', 'left', 'learn', 'marvin', 'README.md', 'go', 'follow', 'tree', 'off', 'validation_list.txt', 'testing_list.txt', 'stop', 'zero', 'six', 'visual', '.DS_Store', 'down', 'forward', 'LICENSE', 'happy', 'house', 'three', '_background_noise_', 'sheila', 'wow', 'seven', 'four', 'yes', 'bird']\n"
          ]
        }
      ],
      "source": [
        "# Check the extracted directory\n",
        "data_path = './speech_commands'\n",
        "print(os.listdir(data_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJJPgQS7zvee"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhpMDKJWz0u9"
      },
      "outputs": [],
      "source": [
        "def load_audio_file(file_path):\n",
        "    signal, sr = librosa.load(file_path, sr=16000)  # Load audio with a sample rate of 16kHz\n",
        "\n",
        "    # Compute Mel-spectrogram\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=40, fmax=8000)\n",
        "\n",
        "    # Convert Mel-spectrogram to MFCC\n",
        "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel_spectrogram), sr=sr, n_mfcc=13)\n",
        "\n",
        "    return mfcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91nH17Gq00PH"
      },
      "outputs": [],
      "source": [
        "# Function to pad or truncate MFCC features to a fixed length\n",
        "def pad_features(mfcc, max_length=44):\n",
        "    if mfcc.shape[1] > max_length:\n",
        "        return mfcc[:, :max_length]  # Truncate if it's too long\n",
        "    elif mfcc.shape[1] < max_length:\n",
        "        pad_width = max_length - mfcc.shape[1]\n",
        "        return np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        return mfcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2p0EiKdz3zS"
      },
      "outputs": [],
      "source": [
        "# Load all files\n",
        "audio_files = glob.glob(f'{data_path}/**/*.wav', recursive=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7vDUCI4z80A"
      },
      "outputs": [],
      "source": [
        "# Extract MFCC features\n",
        "data = []\n",
        "labels = []\n",
        "valid_labels = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go',\n",
        "                'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine',\n",
        "                'bed', 'bird', 'cat', 'dog', 'happy', 'house', 'marvin', 'sheila',\n",
        "                'tree', 'wow', 'forward', 'backward', 'follow', 'learn', 'visual']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXDFKIw5z_eT"
      },
      "outputs": [],
      "source": [
        "for file in audio_files:\n",
        "    label = file.split('/')[-2]  # Extract label from the file path\n",
        "    if label in valid_labels:\n",
        "        mfcc = load_audio_file(file)\n",
        "        padded_mfcc = pad_features(mfcc)  # Pad or truncate to a consistent length\n",
        "        data.append(padded_mfcc)\n",
        "        labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3CWT8Dh0Cg5"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Reshape the data to fit model input (batch_size, height, width, channels)\n",
        "data = np.expand_dims(data, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dKt6FjbHAf_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUUzYHIHHDGj"
      },
      "outputs": [],
      "source": [
        "# Define the input shape\n",
        "input_shape = (13, 44, 1)\n",
        "\n",
        "# Create the model\n",
        "inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "# Use Resizing layer to adjust input to 32x32 for ResNet50\n",
        "x = layers.Resizing(32, 32)(inputs)\n",
        "\n",
        "# Load the base model\n",
        "base_model = ResNet50(weights=None, include_top=False, input_shape=(32, 32, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YB0jq56JWRC"
      },
      "outputs": [],
      "source": [
        "# Build the full model\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(len(valid_labels), activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C8DFYKYJZU3"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6SsjWx2HGGg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2mjlbvXHKBq"
      },
      "outputs": [],
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sFetRTBHM4Y"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7Leqx9nJjS4",
        "outputId": "668234c5-0e99-4873-b937-576ff8d04ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1694/2646\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m33:16\u001b[0m 2s/step - accuracy: 0.0432 - loss: 3.6822"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11qsmxqmJkkn"
      },
      "outputs": [],
      "source": [
        "# Save the trained model to a file\n",
        "model.save('speech_command_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plO6NT04O4Hn"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the model to your local machine\n",
        "files.download('speech_command_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63qBIZ3kWNm0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('speech_command_model.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}